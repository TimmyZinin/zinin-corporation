"""
ðŸ“± Zinin Corp â€” Multi-Platform Content Adapter
Adapts a base post for different platforms (LinkedIn, Telegram, Threads).
Uses free LLM (Llama 3.3 70B) for intelligent rewriting.
Falls back to rule-based adaptation if LLM unavailable.
"""

import logging
import re
from typing import Optional

logger = logging.getLogger(__name__)


# â”€â”€ Platform rules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PLATFORM_RULES = {
    "linkedin": {
        "label": "LinkedIn",
        "max_chars": 3000,
        "tone": "Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹, ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ð¹",
        "hashtags": True,
        "max_hashtags": 5,
        "emoji_level": "minimal",
        "format": "Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾ÑÑ‚ Ñ Ð°Ð±Ð·Ð°Ñ†Ð°Ð¼Ð¸, Ð¿Ð¾Ð´Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ°Ð¼Ð¸ Ð¸ CTA",
        "signature": True,
    },
    "telegram": {
        "label": "Telegram",
        "max_chars": 2000,
        "tone": "Ð¿Ñ€ÑÐ¼Ð¾Ð¹, Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð½Ñ‹Ð¹, Ð±ÐµÐ· Ð²Ð¾Ð´Ñ‹",
        "hashtags": False,
        "max_hashtags": 0,
        "emoji_level": "moderate",
        "format": "ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ð¿Ð¾ÑÑ‚, Ð±ÑƒÐ»Ð»ÐµÑ‚Ñ‹, Ð±ÐµÐ· Ð¿Ð¾Ð´Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²",
        "signature": False,
    },
    "threads": {
        "label": "Threads",
        "max_chars": 500,
        "tone": "Ð¿Ñ€Ð¾Ð²Ð¾ÐºÐ°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹, Ð´Ð¸ÑÐºÑƒÑÑÐ¸Ð¾Ð½Ð½Ñ‹Ð¹",
        "hashtags": True,
        "max_hashtags": 3,
        "emoji_level": "none",
        "format": "1-3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ, Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð² ÐºÐ¾Ð½Ñ†Ðµ Ð´Ð»Ñ Ð´Ð¸ÑÐºÑƒÑÑÐ¸Ð¸",
        "signature": False,
    },
}

_ADAPT_SYSTEM = """You are a content adaptation expert. You rewrite posts for different social platforms.
RULES:
- Keep the core message and key facts EXACTLY
- NEVER invent new data or numbers
- Adapt tone, length, and format for the target platform
- Output ONLY the adapted post text, nothing else
- Write in Russian (unless the original is in English)"""

_ADAPT_PROMPT_TEMPLATE = (
    "ÐÐ´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÐ¹ ÑÑ‚Ð¾Ñ‚ Ð¿Ð¾ÑÑ‚ Ð´Ð»Ñ {platform_label}:\n\n"
    "ÐŸÐ ÐÐ’Ð˜Ð›Ð ÐŸÐ›ÐÐ¢Ð¤ÐžÐ ÐœÐ«:\n"
    "- ÐœÐ°ÐºÑ. Ð´Ð»Ð¸Ð½Ð°: {max_chars} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²\n"
    "- Ð¢Ð¾Ð½: {tone}\n"
    "- Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: {format}\n"
    "- Ð¥ÑÑˆÑ‚ÐµÐ³Ð¸: {hashtag_note}\n"
    "- Ð­Ð¼Ð¾Ð´Ð·Ð¸: {emoji_level}\n"
    "{signature_note}\n\n"
    "ÐžÐ Ð˜Ð“Ð˜ÐÐÐ›Ð¬ÐÐ«Ð™ ÐŸÐžÐ¡Ð¢:\n"
    "{original_text}\n\n"
    "Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ {platform_label}:"
)


# â”€â”€ Core adaptation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def adapt_content(original_text: str, target_platform: str,
                  source_platform: str = "linkedin") -> str:
    """Adapt content for a target platform.

    Uses LLM when available, falls back to rule-based adaptation.
    Returns adapted text or original if adaptation fails.
    """
    if target_platform == source_platform:
        return original_text

    rules = PLATFORM_RULES.get(target_platform)
    if not rules:
        logger.warning(f"Unknown platform: {target_platform}")
        return original_text

    # Try LLM adaptation first
    adapted = _llm_adapt(original_text, target_platform, rules)
    if adapted:
        return adapted

    # Fallback: rule-based adaptation
    return _rule_based_adapt(original_text, target_platform, rules)


def adapt_for_all_platforms(original_text: str,
                            source_platform: str = "linkedin") -> dict[str, str]:
    """Adapt content for all platforms at once.

    Returns dict: {platform_name: adapted_text}.
    Source platform gets original text unchanged.
    """
    result = {}
    for platform in PLATFORM_RULES:
        if platform == source_platform:
            result[platform] = original_text
        else:
            result[platform] = adapt_content(original_text, platform, source_platform)
    return result


# â”€â”€ LLM adaptation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _llm_adapt(original_text: str, target_platform: str,
               rules: dict) -> Optional[str]:
    """Adapt using free LLM. Returns None if unavailable."""
    try:
        from .tech_tools import _call_llm_tech
    except ImportError:
        return None

    signature_note = "- ÐŸÐ¾Ð´Ð¿Ð¸ÑÑŒ Ð±Ñ€ÐµÐ½Ð´Ð° Ð² ÐºÐ¾Ð½Ñ†Ðµ: Ð´Ð°" if rules.get("signature") else ""
    hashtag_note = f"Ð´Ð° (Ð¼Ð°ÐºÑ. {rules.get('max_hashtags', 0)})" if rules.get("hashtags") else "Ð½ÐµÑ‚"

    prompt = _ADAPT_PROMPT_TEMPLATE.format(
        platform_label=rules["label"],
        max_chars=rules["max_chars"],
        tone=rules["tone"],
        format=rules["format"],
        hashtag_note=hashtag_note,
        emoji_level=rules["emoji_level"],
        signature_note=signature_note,
        original_text=original_text[:2000],
    )

    try:
        result = _call_llm_tech(prompt, system=_ADAPT_SYSTEM, max_tokens=1500)
        if result and len(result.strip()) > 20:
            adapted = result.strip()
            # Enforce max length
            if len(adapted) > rules["max_chars"]:
                adapted = _truncate_smart(adapted, rules["max_chars"])
            return adapted
    except Exception as e:
        logger.warning(f"LLM adaptation failed for {target_platform}: {e}")

    return None


# â”€â”€ Rule-based fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _rule_based_adapt(original_text: str, target_platform: str,
                      rules: dict) -> str:
    """Simple rule-based adaptation when LLM is unavailable."""
    text = original_text.strip()

    if target_platform == "telegram":
        # Remove hashtags
        text = re.sub(r'#\w+', '', text).strip()
        # Truncate to limit
        if len(text) > rules["max_chars"]:
            text = _truncate_smart(text, rules["max_chars"])

    elif target_platform == "threads":
        # Take first paragraph or first 2 sentences as hook
        paragraphs = [p.strip() for p in text.split("\n\n") if p.strip()]
        if paragraphs:
            hook = paragraphs[0]
            # If still too long, take first sentence
            if len(hook) > rules["max_chars"]:
                sentences = re.split(r'[.!?]\s+', hook)
                hook = sentences[0] + "." if sentences else hook[:rules["max_chars"]]
            # Add discussion question if space allows
            if len(hook) < rules["max_chars"] - 50:
                hook += "\n\nÐ ÐºÐ°Ðº Ñƒ Ð²Ð°Ñ?"
            text = hook[:rules["max_chars"]]
        else:
            text = text[:rules["max_chars"]]

    elif target_platform == "linkedin":
        # Ensure not too long
        if len(text) > rules["max_chars"]:
            text = _truncate_smart(text, rules["max_chars"])

    return text


def _truncate_smart(text: str, max_chars: int) -> str:
    """Truncate text at sentence boundary, not mid-word."""
    if len(text) <= max_chars:
        return text

    # Find last sentence end before limit
    truncated = text[:max_chars]
    last_period = max(truncated.rfind('.'), truncated.rfind('!'), truncated.rfind('?'))

    if last_period > max_chars * 0.5:
        return truncated[:last_period + 1]

    # Fallback: truncate at last space
    last_space = truncated.rfind(' ')
    if last_space > max_chars * 0.5:
        return truncated[:last_space] + "..."

    return truncated + "..."
