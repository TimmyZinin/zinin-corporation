"""
Agent Improvement Advisor â€” proactive improvement system for Zinin Corp agents.

CTO ĞœĞ°Ñ€Ñ‚Ğ¸Ğ½ reads agent YAMLs, researches best practices via web,
analyzes via free LLM, and generates structured improvement proposals.
"""

import json
import logging
import os
import time
from datetime import datetime
from typing import Optional, Type

from crewai.tools import BaseTool
from pydantic import BaseModel, Field

from .tech_tools import _call_llm_tech

logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Agent names for iteration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_AGENT_NAMES = ["manager", "accountant", "automator", "yuki", "designer"]

_AGENT_LABELS = {
    "manager": "ğŸ‘‘ ĞĞ»ĞµĞºÑĞµĞ¹ (CEO)",
    "accountant": "ğŸ¦ ĞœĞ°Ñ‚Ñ‚Ğ¸Ğ°Ñ (CFO)",
    "automator": "âš™ï¸ ĞœĞ°Ñ€Ñ‚Ğ¸Ğ½ (CTO)",
    "yuki": "ğŸ“± Ğ®ĞºĞ¸ (SMM)",
    "designer": "ğŸ¨ Ğ Ğ°Ğ¹Ğ°Ğ½ (Designer)",
}

_MODEL_COSTS = {
    "openrouter/anthropic/claude-sonnet-4": {"name": "Claude Sonnet 4", "tier": "sonnet", "cost_1k": 0.015},
    "openrouter/anthropic/claude-3-5-haiku-latest": {"name": "Claude 3.5 Haiku", "tier": "haiku", "cost_1k": 0.001},
    "openrouter/anthropic/claude-3.5-haiku": {"name": "Claude 3.5 Haiku", "tier": "haiku", "cost_1k": 0.001},
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Proposal Storage
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _proposals_path() -> str:
    for p in ["/app/data/cto_proposals.json", "data/cto_proposals.json"]:
        if os.path.isdir(os.path.dirname(p)):
            return p
    return "data/cto_proposals.json"


def _load_proposals() -> dict:
    path = _proposals_path()
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            pass
    return {
        "proposals": [],
        "stats": {"total_generated": 0, "approved": 0, "rejected": 0, "conditions": 0},
        "last_run": None,
    }


def _save_proposals(data: dict):
    path = _proposals_path()
    os.makedirs(os.path.dirname(path), exist_ok=True)
    # Cap at 200 proposals
    data["proposals"] = data["proposals"][-200:]
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Agent YAML Reading
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _agent_yaml_dir() -> str:
    for d in ["/app/agents", "agents"]:
        if os.path.isdir(d):
            return d
    return "agents"


def _read_all_agent_yamls() -> dict:
    """Read all agent YAMLs. Returns {name: config_dict}."""
    import yaml

    result = {}
    base_dir = _agent_yaml_dir()
    for name in _AGENT_NAMES:
        path = os.path.join(base_dir, f"{name}.yaml")
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    result[name] = yaml.safe_load(f) or {}
            except Exception as e:
                logger.warning(f"Failed to read {path}: {e}")
                result[name] = {"error": str(e)}
    return result


def _summarize_agent(name: str, config: dict) -> str:
    """Create concise summary of agent for LLM context."""
    label = _AGENT_LABELS.get(name, name)
    role = config.get("role", "?")
    llm = config.get("llm", "?")
    model_info = _MODEL_COSTS.get(llm, {"name": llm, "tier": "?", "cost_1k": 0})
    goal = config.get("goal", "")
    # Truncate backstory to first 500 chars for summary
    backstory = config.get("backstory", "")
    backstory_preview = backstory[:500] + "..." if len(backstory) > 500 else backstory

    max_iter = config.get("max_iter", "?")
    allow_delegation = config.get("allow_delegation", False)
    memory = config.get("memory", False)

    return (
        f"--- {label} ---\n"
        f"Role: {role}\n"
        f"Model: {model_info['name']} (tier: {model_info['tier']}, ~${model_info['cost_1k']}/1k tokens)\n"
        f"Max iterations: {max_iter}, Delegation: {allow_delegation}, Memory: {memory}\n"
        f"Goal: {goal[:300]}\n"
        f"Backstory preview: {backstory_preview}\n"
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Web Research
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _research_best_practices(topic: str) -> list[dict]:
    """Search DuckDuckGo for best practices. Returns [{title, url, snippet}]."""
    try:
        from duckduckgo_search import DDGS
    except ImportError:
        logger.warning("duckduckgo_search not installed, skipping web research")
        return []

    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(
                f"CrewAI agent {topic} best practices prompt engineering 2025 2026",
                max_results=5,
            ))
        return [
            {
                "title": r.get("title", ""),
                "url": r.get("href", ""),
                "snippet": r.get("body", ""),
            }
            for r in results
        ]
    except Exception as e:
        logger.warning(f"Web research failed: {e}")
        return []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM Analysis Prompts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_IMPROVEMENT_SYSTEM = """Ğ¢Ñ‹ â€” ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ prompt engineering Ğ´Ğ»Ñ Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸-Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼ CrewAI.
Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ YAML-ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ ĞĞ”ĞĞ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ.

Ğ¢Ğ¸Ğ¿Ñ‹ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¹:
1. PROMPT â€” ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ backstory, goal Ğ¸Ğ»Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹
2. TOOL â€” Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° Ğ¸Ğ»Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ…
3. MODEL_TIER â€” Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ ÑĞ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ (haikuâ†”sonnet) Ñ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ ÑÑ‚Ğ¾Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ (ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ JSON, Ğ±ĞµĞ· markdown):
{
    "proposal_type": "prompt Ğ¸Ğ»Ğ¸ tool Ğ¸Ğ»Ğ¸ model_tier",
    "title": "ĞšÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº Ğ´Ğ¾ 60 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²",
    "description": "ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ (200-400 ÑĞ»Ğ¾Ğ²)",
    "current_state": "Ğ§Ñ‚Ğ¾ ÑĞµĞ¹Ñ‡Ğ°Ñ Ğ¸ Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ ÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°",
    "proposed_change": "ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ¼ ĞºĞ¾Ğ´Ğ°/Ñ‚ĞµĞºÑÑ‚Ğ°",
    "confidence_score": 0.85,
    "reasoning": "ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ ÑÑ‚Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°"
}

ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ:
- ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ™ YAML. ĞĞ• Ğ²Ñ‹Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹.
- Ğ•ÑĞ»Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚ Ñ…Ğ¾Ñ€Ğ¾Ñˆ â€” Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸ Ğ¼ĞµĞ»ĞºĞ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ Ñ Ğ½Ğ¸Ğ·ĞºĞ¸Ğ¼ confidence (0.3-0.5).
- Ğ’ÑĞµĞ³Ğ´Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°Ğ¹ ĞšĞĞĞšĞ Ğ•Ğ¢ĞĞ«Ğ• Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ, Ğ½Ğµ Ğ¾Ğ±Ñ‰Ğ¸Ğµ ÑĞ»Ğ¾Ğ²Ğ°.
- confidence_score: 0.9+ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾Ğµ, 0.7-0.9 Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾Ğµ, 0.5-0.7 Ğ¶ĞµĞ»Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ, <0.5 Ğ¼ĞµĞ»ĞºĞ¾Ğµ.
- ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼ JSON, Ğ±ĞµĞ· Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ¾/Ğ¿Ğ¾ÑĞ»Ğµ."""

_MODEL_AUDIT_SYSTEM = """Ğ¢Ñ‹ â€” ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¿Ğ¾ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚ Ğ½Ğ° LLM Ğ² Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸-Ğ°Ğ³ĞµĞ½Ñ‚Ğ½Ñ‹Ñ… ÑĞ¸ÑÑ‚ĞµĞ¼Ğ°Ñ….
ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ»Ğ¸ Ğ¼ĞµĞ½ÑÑ‚ÑŒ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.

Claude Sonnet 4: ~$0.015/1k tokens â€” Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ, Ğ´ĞµĞ»ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸
Claude 3.5 Haiku: ~$0.001/1k tokens â€” Ğ´Ğ»Ñ Ñ€ÑƒÑ‚Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡, Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°, Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ (ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ JSON, Ğ±ĞµĞ· markdown):
{
    "recommendations": [
        {
            "agent": "Ğ¸Ğ¼Ñ_Ğ°Ğ³ĞµĞ½Ñ‚Ğ°",
            "current_tier": "sonnet Ğ¸Ğ»Ğ¸ haiku",
            "recommended_tier": "sonnet Ğ¸Ğ»Ğ¸ haiku",
            "action": "keep Ğ¸Ğ»Ğ¸ upgrade Ğ¸Ğ»Ğ¸ downgrade",
            "reasoning": "ĞŸĞ¾Ñ‡ĞµĞ¼Ñƒ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼",
            "estimated_monthly_saving_usd": 0.0
        }
    ],
    "summary": "ĞĞ±Ñ‰Ğ¸Ğ¹ Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼"
}

ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¼ JSON."""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tool: Agent Improvement Advisor
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ImprovementInput(BaseModel):
    action: str = Field(
        ...,
        description=(
            "Action: 'analyze' (analyze ONE agent and propose improvement), "
            "'analyze_all' (pick least-recently-improved agent and analyze), "
            "'list_proposals' (show recent proposals with statuses), "
            "'get_proposal' (get specific proposal by id), "
            "'model_audit' (audit model tiers for all agents), "
            "'self_reflect' (CTO analyzes himself)"
        ),
    )
    target_agent: Optional[str] = Field(
        None,
        description=f"Agent key for 'analyze'. Options: {', '.join(_AGENT_NAMES)}",
    )
    proposal_id: Optional[str] = Field(
        None,
        description="Proposal ID for 'get_proposal'",
    )


class AgentImprovementAdvisor(BaseTool):
    name: str = "Agent Improvement Advisor"
    description: str = (
        "Proactive agent improvement system. Reads agent YAML configs, "
        "researches best practices via web search, analyzes with LLM, "
        "and generates structured improvement proposals. "
        "Can analyze any agent including CTO himself. "
        "Actions: analyze, analyze_all, list_proposals, get_proposal, model_audit, self_reflect."
    )
    args_schema: Type[BaseModel] = ImprovementInput

    def _run(self, action: str, target_agent: str = None, proposal_id: str = None) -> str:
        if action == "analyze":
            return self._analyze_agent(target_agent)

        if action == "analyze_all":
            return self._analyze_least_recent()

        if action == "list_proposals":
            return self._list_proposals()

        if action == "get_proposal":
            return self._get_proposal(proposal_id)

        if action == "model_audit":
            return self._model_audit()

        if action == "self_reflect":
            return self._analyze_agent("automator")

        return (
            f"Unknown action: {action}. "
            "Use: analyze, analyze_all, list_proposals, get_proposal, model_audit, self_reflect"
        )

    # â”€â”€ analyze â”€â”€

    def _analyze_agent(self, target_agent: str = None) -> str:
        if not target_agent:
            return f"Error: need target_agent. Options: {', '.join(_AGENT_NAMES)}"
        if target_agent not in _AGENT_NAMES:
            return f"Unknown agent: {target_agent}. Options: {', '.join(_AGENT_NAMES)}"

        agents = _read_all_agent_yamls()
        config = agents.get(target_agent, {})
        if not config or "error" in config:
            return f"Error reading YAML for {target_agent}: {config.get('error', 'not found')}"

        # Full YAML for analysis
        full_yaml = json.dumps(config, ensure_ascii=False, indent=2)
        if len(full_yaml) > 6000:
            full_yaml = full_yaml[:6000] + "\n... (truncated)"

        # Web research
        role = config.get("role", target_agent)
        research = _research_best_practices(role)
        research_text = ""
        if research:
            research_text = "\n\nBEST PRACTICES FROM WEB:\n"
            for r in research[:3]:
                research_text += f"- {r['title']}: {r['snippet'][:200]}\n"

        prompt = (
            f"ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° '{_AGENT_LABELS.get(target_agent, target_agent)}' "
            f"Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸ ĞĞ”ĞĞ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğµ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğµ.\n\n"
            f"YAML CONFIG:\n```\n{full_yaml}\n```\n"
            f"{research_text}\n"
            f"Ğ’ĞµÑ€Ğ½Ğ¸ JSON Ñ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ĞµĞ¼."
        )

        llm_result = _call_llm_tech(prompt, system=_IMPROVEMENT_SYSTEM, max_tokens=2000)
        if not llm_result:
            return "âŒ LLM Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ OPENROUTER_API_KEY."

        # Parse JSON from LLM response
        proposal_data = self._parse_proposal_json(llm_result)
        if not proposal_data:
            return f"âŒ LLM Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ½ĞµĞ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ JSON. Raw:\n{llm_result[:500]}"

        # Create proposal
        now = datetime.now()
        proposal_id_str = f"prop_{now.strftime('%Y%m%d_%H%M')}_{target_agent}"
        proposal = {
            "id": proposal_id_str,
            "created_at": now.isoformat(),
            "target_agent": target_agent,
            "proposal_type": proposal_data.get("proposal_type", "prompt"),
            "title": proposal_data.get("title", "Ğ‘ĞµĞ· Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°"),
            "description": proposal_data.get("description", ""),
            "current_state": proposal_data.get("current_state", ""),
            "proposed_change": proposal_data.get("proposed_change", ""),
            "research_sources": [r["url"] for r in research[:3]] if research else [],
            "confidence_score": min(max(float(proposal_data.get("confidence_score", 0.5)), 0.0), 1.0),
            "status": "pending",
            "conditions": "",
            "reviewed_at": None,
        }

        # Save
        data = _load_proposals()
        data["proposals"].append(proposal)
        data["stats"]["total_generated"] = data["stats"].get("total_generated", 0) + 1
        data["last_run"] = now.isoformat()
        _save_proposals(data)

        label = _AGENT_LABELS.get(target_agent, target_agent)
        type_labels = {"prompt": "ğŸ“ ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚", "tool": "ğŸ”§ Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚", "model_tier": "ğŸ§  ĞœĞ¾Ğ´ĞµĞ»ÑŒ"}
        ptype = type_labels.get(proposal["proposal_type"], proposal["proposal_type"])

        return (
            f"â•â•â• ĞĞĞ’ĞĞ• ĞŸĞ Ğ•Ğ”Ğ›ĞĞ–Ğ•ĞĞ˜Ğ• â•â•â•\n"
            f"ID: {proposal['id']}\n"
            f"ĞĞ³ĞµĞ½Ñ‚: {label}\n"
            f"Ğ¢Ğ¸Ğ¿: {ptype}\n"
            f"Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ: {proposal['confidence_score']:.0%}\n\n"
            f"ğŸ“‹ {proposal['title']}\n\n"
            f"{proposal['description']}\n\n"
            f"Ğ¢ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ: {proposal['current_state']}\n\n"
            f"ĞŸÑ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµĞ¼Ğ¾Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ: {proposal['proposed_change']}"
        )

    # â”€â”€ analyze_all â”€â”€

    def _analyze_least_recent(self) -> str:
        """Pick the agent that was least recently analyzed and run analyze."""
        data = _load_proposals()
        proposals = data.get("proposals", [])

        # Count proposals per agent
        last_analyzed = {}
        for p in proposals:
            agent = p.get("target_agent")
            ts = p.get("created_at", "")
            if agent and ts > last_analyzed.get(agent, ""):
                last_analyzed[agent] = ts

        # Find least recent (or never analyzed)
        target = None
        oldest_ts = None
        for name in _AGENT_NAMES:
            ts = last_analyzed.get(name)
            if ts is None:
                target = name
                break
            if oldest_ts is None or ts < oldest_ts:
                oldest_ts = ts
                target = name

        if not target:
            target = _AGENT_NAMES[0]

        return self._analyze_agent(target)

    # â”€â”€ list_proposals â”€â”€

    def _list_proposals(self) -> str:
        data = _load_proposals()
        proposals = data.get("proposals", [])
        stats = data.get("stats", {})

        if not proposals:
            return (
                "ĞĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹. Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸ action='analyze_all' Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸.\n"
                f"Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°: {json.dumps(stats, ensure_ascii=False)}"
            )

        lines = [
            f"â•â•â• ĞŸĞ Ğ•Ğ”Ğ›ĞĞ–Ğ•ĞĞ˜Ğ¯ ({len(proposals)} Ğ²ÑĞµĞ³Ğ¾) â•â•â•",
            f"Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°: Ğ¾Ğ´Ğ¾Ğ±Ñ€ĞµĞ½Ğ¾ {stats.get('approved', 0)}, "
            f"Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¾ {stats.get('rejected', 0)}, "
            f"Ñ ÑƒÑĞ»Ğ¾Ğ²Ğ¸ÑĞ¼Ğ¸ {stats.get('conditions', 0)}",
            "",
        ]

        status_icons = {
            "pending": "â³",
            "approved": "âœ…",
            "rejected": "âŒ",
            "conditions": "ğŸ“",
        }

        for p in proposals[-10:]:
            icon = status_icons.get(p.get("status"), "?")
            label = _AGENT_LABELS.get(p.get("target_agent", ""), p.get("target_agent", "?"))
            confidence = p.get("confidence_score", 0)
            lines.append(
                f"  {icon} [{p['id']}] {label} â€” {p.get('title', '?')} "
                f"(confidence: {confidence:.0%})"
            )

        return "\n".join(lines)

    # â”€â”€ get_proposal â”€â”€

    def _get_proposal(self, proposal_id: str = None) -> str:
        if not proposal_id:
            return "Error: need proposal_id"
        data = _load_proposals()
        for p in data.get("proposals", []):
            if p.get("id") == proposal_id:
                return json.dumps(p, ensure_ascii=False, indent=2)
        return f"Proposal '{proposal_id}' not found."

    # â”€â”€ model_audit â”€â”€

    def _model_audit(self) -> str:
        agents = _read_all_agent_yamls()
        summaries = []
        for name in _AGENT_NAMES:
            config = agents.get(name, {})
            if config and "error" not in config:
                summaries.append(_summarize_agent(name, config))

        prompt = (
            "ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ğ¸ Ğ°ÑƒĞ´Ğ¸Ñ‚ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ‚Ğ¸Ñ€Ğ¾Ğ² Ğ²ÑĞµÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Zinin Corp.\n"
            "ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸, ĞºĞ¾Ğ¼Ñƒ ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¿Ğ¾Ğ²Ñ‹ÑĞ¸Ñ‚ÑŒ/Ğ¿Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ.\n\n"
            "ĞĞ“Ğ•ĞĞ¢Ğ«:\n" + "\n".join(summaries) + "\n\n"
            "Ğ’ĞµÑ€Ğ½Ğ¸ JSON Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸ÑĞ¼Ğ¸."
        )

        result = _call_llm_tech(prompt, system=_MODEL_AUDIT_SYSTEM, max_tokens=2000)
        if not result:
            return "âŒ LLM Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ´Ğ»Ñ Ğ°ÑƒĞ´Ğ¸Ñ‚Ğ°."

        # Try to parse JSON
        try:
            parsed = self._extract_json(result)
            if parsed:
                recs = parsed.get("recommendations", [])
                lines = ["â•â•â• ĞĞ£Ğ”Ğ˜Ğ¢ ĞœĞĞ”Ğ•Ğ›Ğ¬ĞĞ«Ğ¥ Ğ¢Ğ˜Ğ ĞĞ’ â•â•â•", ""]
                for rec in recs:
                    agent_label = _AGENT_LABELS.get(rec.get("agent", ""), rec.get("agent", "?"))
                    action = rec.get("action", "?")
                    action_icon = {"keep": "âœ…", "upgrade": "â¬†ï¸", "downgrade": "â¬‡ï¸"}.get(action, "?")
                    lines.append(
                        f"  {action_icon} {agent_label}: {rec.get('current_tier', '?')} â†’ "
                        f"{rec.get('recommended_tier', '?')} ({action})"
                    )
                    lines.append(f"    {rec.get('reasoning', '')}")
                    saving = rec.get("estimated_monthly_saving_usd", 0)
                    if saving:
                        lines.append(f"    Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ: ~${saving:.2f}/Ğ¼ĞµÑ")
                    lines.append("")

                summary = parsed.get("summary", "")
                if summary:
                    lines.append(f"Ğ’Ñ‹Ğ²Ğ¾Ğ´: {summary}")
                return "\n".join(lines)
        except Exception:
            pass

        return f"â•â•â• ĞĞ£Ğ”Ğ˜Ğ¢ ĞœĞĞ”Ğ•Ğ›Ğ¬ĞĞ«Ğ¥ Ğ¢Ğ˜Ğ ĞĞ’ â•â•â•\n\n{result}"

    # â”€â”€ helpers â”€â”€

    @staticmethod
    def _parse_proposal_json(text: str) -> Optional[dict]:
        """Extract and parse proposal JSON from LLM response."""
        # Try direct parse
        try:
            return json.loads(text.strip())
        except json.JSONDecodeError:
            pass

        # Try extracting JSON from markdown code block
        for marker in ["```json", "```"]:
            if marker in text:
                start = text.index(marker) + len(marker)
                end = text.index("```", start) if "```" in text[start:] else len(text)
                try:
                    return json.loads(text[start:start + end - start].strip())
                except (json.JSONDecodeError, ValueError):
                    pass

        # Try finding { ... } block
        brace_start = text.find("{")
        brace_end = text.rfind("}")
        if brace_start >= 0 and brace_end > brace_start:
            try:
                return json.loads(text[brace_start:brace_end + 1])
            except json.JSONDecodeError:
                pass

        return None

    @staticmethod
    def _extract_json(text: str) -> Optional[dict]:
        """Same as _parse_proposal_json but for any JSON."""
        return AgentImprovementAdvisor._parse_proposal_json(text)
