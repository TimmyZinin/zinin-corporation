"""Market Listener ‚Äî daily career market trend scanner.

Scans web for career/HR trends and generates topic suggestions
for Yuki content pipeline. Uses DuckDuckGo search + LLM synthesis.
"""

import json
import logging
import os
import threading
from datetime import date, datetime

logger = logging.getLogger(__name__)

_DATA_DIR = os.path.join(os.path.dirname(__file__), "..", "data")
_INSIGHTS_PATH = os.path.join(_DATA_DIR, "market_insights.json")
_lock = threading.Lock()

SEARCH_QUERIES = [
    "—Ä—ã–Ω–æ–∫ —Ç—Ä—É–¥–∞ —Ç—Ä–µ–Ω–¥—ã 2026 site:hh.ru OR site:linkedin.com",
    "–∫–∞—Ä—å–µ—Ä–∞ –ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç—ã —Ç—Ä–µ–Ω–¥—ã –Ω–æ–≤–æ—Å—Ç–∏",
    "AI HR –Ω–∞–π–º –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–∏",
    "remote work hybrid 2026 trends",
]

_SYNTHESIS_PROMPT = """–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –∫–∞—Ä—å–µ—Ä–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞. –ù–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
–≤—ã–¥–µ–ª–∏ 5 –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ç–µ–º –¥–ª—è LinkedIn-–ø–æ—Å—Ç–æ–≤ –ø—Ä–æ –∫–∞—Ä—å–µ—Ä—É –∏ –ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç—ã.

–ü–æ–∏—Å–∫–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:
{snippets}

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON-–º–∞—Å—Å–∏–≤ –∏–∑ 5 —Å—Ç—Ä–æ–∫ (—Ç–µ–º), –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
–ö–∞–∂–¥–∞—è —Ç–µ–º–∞ ‚Äî 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è, –∞–∫—Ç—É–∞–ª—å–Ω–∞—è, –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω–∞—è.
–ü—Ä–∏–º–µ—Ä: ["–¢–µ–º–∞ 1", "–¢–µ–º–∞ 2", ...]"""


def _insights_path() -> str:
    return _INSIGHTS_PATH


def _load_insights() -> dict:
    path = _insights_path()
    with _lock:
        try:
            if os.path.exists(path):
                with open(path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                    if isinstance(data, dict):
                        return data
        except Exception as e:
            logger.warning(f"Failed to load market insights: {e}")
    return {"scans": [], "updated_at": ""}


def _save_insights(data: dict) -> bool:
    path = _insights_path()
    with _lock:
        try:
            os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
            with open(path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            logger.warning(f"Failed to save market insights: {e}")
            return False


def get_today_topics() -> list[str]:
    """Return cached topics for today. Empty list if no scan yet."""
    today_str = date.today().isoformat()
    data = _load_insights()
    for scan in reversed(data.get("scans", [])):
        if scan.get("date") == today_str:
            return scan.get("topics", [])
    return []


async def run_daily_scan() -> list[str]:
    """Run web search + LLM synthesis to generate topic suggestions.

    Returns list of 3-5 topic strings.
    """
    import asyncio

    # Step 1: Search
    snippets = []
    try:
        from .tools.tech_tools import WebSearchTool
        search_tool = WebSearchTool()
        for query in SEARCH_QUERIES:
            try:
                result = await asyncio.to_thread(search_tool._run, query=query)
                if result:
                    snippets.append(result[:500])
            except Exception as e:
                logger.warning(f"Search failed for '{query[:30]}': {e}")
    except Exception as e:
        logger.warning(f"WebSearchTool import failed: {e}")

    if not snippets:
        logger.warning("No search results for market listener")
        return []

    # Step 2: LLM synthesis
    topics = []
    try:
        combined = "\n---\n".join(snippets)
        prompt = _SYNTHESIS_PROMPT.format(snippets=combined[:3000])

        from .tools.tech_tools import _call_llm_tech
        response = await asyncio.to_thread(_call_llm_tech, prompt)

        # Parse JSON array from response
        if response:
            # Try to extract JSON array
            start = response.find("[")
            end = response.rfind("]")
            if start >= 0 and end > start:
                topics = json.loads(response[start:end + 1])
                topics = [str(t) for t in topics if isinstance(t, str)][:5]
    except Exception as e:
        logger.error(f"LLM synthesis failed: {e}", exc_info=True)

    if not topics:
        return []

    # Step 3: Save
    data = _load_insights()
    data["scans"].append({
        "date": date.today().isoformat(),
        "topics": topics,
        "snippets_count": len(snippets),
        "created_at": datetime.now().isoformat(),
    })
    # Keep last 30 days
    if len(data["scans"]) > 30:
        data["scans"] = data["scans"][-30:]
    data["updated_at"] = datetime.now().isoformat()
    _save_insights(data)

    logger.info(f"Market listener: {len(topics)} topics generated")
    return topics


def format_topics_for_menu(topics: list[str]) -> str:
    """Format topics for Telegram message."""
    if not topics:
        return "üí° –ù–µ—Ç —Å–≤–µ–∂–∏—Ö —Ç–µ–º. –ó–∞–ø—É—Å—Ç–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∑–∂–µ."

    lines = ["üí° –ì–æ—Ä—è—á–∏–µ —Ç–µ–º—ã —Å–µ–≥–æ–¥–Ω—è:"]
    for i, t in enumerate(topics, 1):
        lines.append(f"  {i}. {t[:80]}")
    return "\n".join(lines)
